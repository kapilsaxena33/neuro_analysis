{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place Cell Identification\n",
    "\n",
    "#### Three inputs:\n",
    "#### 1. input_animal:\n",
    "- H0466\n",
    "- H0422\n",
    "- etc\n",
    "\n",
    "#### 2. input_session: \n",
    "- all = run through all sessions and stages\n",
    "- N01\n",
    "- N02\n",
    "- I01\n",
    "- I02\n",
    "- A01\n",
    "- A02\n",
    "- P01\n",
    "- P02\n",
    "\n",
    "#### 3. input_stage:\n",
    "- PRE\n",
    "- SAM\n",
    "- CHO\n",
    "- PRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_animal = 'H0466'\n",
    "input_session = ['all']\n",
    "input_stage = ['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import ast\n",
    "\n",
    "import place_cell_functions\n",
    "import multiprocessing as mp\n",
    "from _thread import start_new_thread\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    \n",
    "#plotting params\n",
    "mpl.rcParams['axes.facecolor'] = 'white'\n",
    "mpl.rcParams['axes.edgecolor'] = 'black'\n",
    "mpl.rcParams['axes.linewidth'] = '0.5'\n",
    "mpl.rcParams['axes.labelsize'] = '8'\n",
    "mpl.rcParams['axes.labelcolor'] = 'black'\n",
    "\n",
    "mpl.rcParams['xtick.color'] = 'black'\n",
    "mpl.rcParams['xtick.labelsize'] = '4'\n",
    "mpl.rcParams['ytick.labelsize'] = '4'\n",
    "mpl.rcParams['ytick.color'] = 'black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (11,12,13,14,15,17,19,21,22,23,24,25,26,28,31,32,33,36,37,38,39,40,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,66,67,70,72,73,74,76,79,80,82,86,87,88,89,90,92,94,95,97,99,100,103,104,105,106,108,109,111,112,113,114,115,116,117,118,119,121,122,124,125,126,129,130,131,132,134,135,137,141,143,144,145,146,147,148,149,151,152,154,155,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Read iin LR events and trace files\n",
    "all_events_dlc = pd.read_csv('/Users/rufusmitchell-heggs/Desktop/data_analysis/preprocessing/event_arena/'+input_animal+'/output_directory/'+input_animal+'_event_dlc_LR.csv')\n",
    "all_traces_dlc = pd.read_csv('/Users/rufusmitchell-heggs/Desktop/data_analysis/preprocessing/event_arena/'+input_animal+'/output_directory/'+input_animal+'_trace_dlc_LR.csv')\n",
    "\n",
    "if input_session[0] == 'all':\n",
    "    input_session = list(set(list(all_traces_dlc['Session'])))\n",
    "if input_stage[0] == 'all':\n",
    "    input_stage = list(set(list(all_traces_dlc['stage'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01 CHO\n",
      "P01 PRE\n",
      "P01 SAM\n",
      "P01 PRO\n",
      "I02 CHO\n",
      "I02 PRE\n",
      "I02 SAM\n",
      "I02 PRO\n",
      "I01 CHO\n",
      "I01 PRE\n",
      "I01 SAM\n",
      "I01 PRO\n",
      "P02 CHO\n",
      "P02 PRE\n",
      "P02 SAM\n",
      "P02 PRO\n",
      "A01 CHO\n",
      "A01 PRE\n",
      "A01 SAM\n",
      "A01 PRO\n",
      "N01 CHO\n",
      "N01 PRE\n"
     ]
    }
   ],
   "source": [
    "for session in input_session:\n",
    "    for stage in input_stage:\n",
    "        print(session, stage)\n",
    "        \n",
    "        #Session and stage selection based on input\n",
    "        traces = all_traces_dlc[all_traces_dlc['Session']==session][all_traces_dlc[all_traces_dlc['Session']==session]['stage']==stage]\n",
    "        events = all_events_dlc[all_events_dlc['Session']==session][all_events_dlc[all_events_dlc['Session']==session]['stage']==stage]\n",
    "        traces = traces.reset_index(drop=True)\n",
    "        events = events.reset_index(drop=True)\n",
    "        \n",
    "        #Remove any cells that are not registered during that session/stage\n",
    "        traces = traces.loc[:,(traces!=' nan').all()]\n",
    "\n",
    "        #List of cell IDs and their respective traces\n",
    "        cells = traces.columns\n",
    "        events = events[events.columns.intersection(cells)]\n",
    "        cell_ids = events.columns[11:]\n",
    "        \n",
    "        #Assign variable name to global identity\n",
    "        cells = cell_ids\n",
    "        trace_dlc = traces\n",
    "        events_dlc = events\n",
    "        \n",
    "        if len(events_dlc) != 0:\n",
    "\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "    #         # CRITERIA 1 - Cell sorting to manually remove bad traces\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "    #         num_cells_analysed = 0\n",
    "    #         for cell in cells:\n",
    "\n",
    "    #             #Allow user to see how many cells they have looked through\n",
    "    #             num_cells_analysed +=1\n",
    "    #             num_cells_left = len(cells)-1\n",
    "    #             print(cell, num_cells_analysed,'/',num_cells_left)\n",
    "\n",
    "    #             #plot the raw traces and overlapping events\n",
    "    #             plt.figure(figsize=(8, 1), dpi=400)\n",
    "    #             plt.plot(trace_dlc[str(cell)].astype(float), linewidth=0.5)\n",
    "    #             plt.plot(events_dlc[str(cell)].astype(float), linewidth=1)\n",
    "    #             plt.show()\n",
    "\n",
    "    #             #Option to remove any bad cells\n",
    "    #             good_events = input(\"Are all events good - y/n?\")\n",
    "    #             if good_events != 'y':\n",
    "    #                 print(bcolors.FAIL+cell,'Dropped'+bcolors.ENDC)\n",
    "    #                 trace_dlc = trace_dlc.drop([cell], axis=1)\n",
    "    #                 events_dlc = events_dlc.drop([cell], axis=1)\n",
    "\n",
    "    #             else:\n",
    "    #                 print(bcolors.OKGREEN+cell,'Accepted'+bcolors.ENDC)\n",
    "\n",
    "    #         #Update cells being analysed list\n",
    "    #         cells = events_dlc.columns[11:]\n",
    "\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "            # CRITERIA 2 - all cells with events lower than 0.3 = 0\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "            # for cell in cells:\n",
    "            #     a = np.array(events_dlc[cell].values.tolist())\n",
    "            #     events_dlc[str(cell)] = np.where(a <= 0.3, 0, a).tolist() # <--- Condition, ignore events lower than 0.3\n",
    "            #     events_dlc[str(cell)] = np.where(a >= 0.3, 1, a).tolist() # <--- Binarize events\n",
    "            #     if sum(events_dlc[cell])<3:\n",
    "            #         events_dlc = events_dlc.drop([cell], axis=1)\n",
    "\n",
    "            for cell in cells:\n",
    "                a = np.array(events_dlc[cell].values.tolist())\n",
    "                events_dlc[str(cell)] = np.where(a > 0, 1, a).tolist() # <--- Binarize events\n",
    "                if sum(events_dlc[cell])<3:\n",
    "                    events_dlc = events_dlc.drop([cell], axis=1)\n",
    "                    trace_dlc = trace_dlc.drop([cell], axis=1)\n",
    "\n",
    "            cells = events_dlc.columns[11:]\n",
    "            for cell in trace_dlc.columns:\n",
    "                if cell not in events.columns:\n",
    "                    trace_dlc = trace_dlc.drop([cell], axis=1)\n",
    "\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "            # OCCUPANCY VECTOR GENERATOR\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "\n",
    "            #Defining the boundaries of the arena\n",
    "            xedges = np.arange(0, 700, 720/33)\n",
    "            yedges = np.arange(0, 600, 720/33)\n",
    "\n",
    "            #Extract the DLC x,y coordinates\n",
    "            x = events_dlc['x']\n",
    "            y = events_dlc['y']\n",
    "\n",
    "            #Create occupancy map vector\n",
    "            occupancy_map_vector = []\n",
    "            for x_pos, y_pos in zip(x,y):\n",
    "                for y_bin in range(len(yedges)):\n",
    "                    if y_bin < len(yedges)-1:\n",
    "                        if  yedges[y_bin] <= y_pos <= yedges[y_bin+1]:\n",
    "                            for x_bin in range(len(xedges)):\n",
    "                                if x_bin < len(xedges)-1:\n",
    "                                    if xedges[x_bin] <= x_pos <= xedges[x_bin+1]:\n",
    "                                        occupancy_map_vector.append(int(str(y_bin)+str(x_bin)))\n",
    "\n",
    "            # ----------------------------------------------------------------------------------------                         \n",
    "            # SPATIAL MUTUAL INFORMATION for each cell, the percentile and the shuffled distribution\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "            shuffles = 10\n",
    "            pool = mp.Pool(processes=4)\n",
    "            results = [pool.apply_async(place_cell_functions.mi_perc_dis, args=(np.array(events_dlc[str(cell)]),occupancy_map_vector, shuffles)) for cell in cells]\n",
    "            mi_all, perc_all, dist_all = np.array([p.get() for p in results]).transpose()\n",
    "            perc_all = np.array([item for sublist in perc_all for item in sublist])\n",
    "            end = time.time()\n",
    "            \n",
    "            # ----------------------------------------------------------------------------------------                         \n",
    "            # Additional info columns:\n",
    "            # Bin centre, number of events at bin centre, \n",
    "            # Euclidean distance from each sandwell, rewarded sandwell\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "            max_events_all, bin_centres_all, bin_occupancy_all = place_cell_functions.occupancy_map(events_dlc, cells)\n",
    "            \n",
    "            #Coordinates for each Sandwell\n",
    "            sw1_loc,sw2_loc,sw3_loc = np.array(ast.literal_eval(events_dlc['SW_locs'][0]))\n",
    "            \n",
    "            place_cell_status_all = []\n",
    "            #Iterate through all bin centres and find euclidean distance to sandwell\n",
    "            euc_dis_sw1_all, euc_dis_sw2_all, euc_dis_sw3_all = [[],[],[]]\n",
    "            for cell_bin_center, cell_bin_occupancy in zip(bin_centres_all, bin_occupancy_all):\n",
    "                \n",
    "                euc_dis_sw1, euc_dis_sw2, euc_dis_sw3 = [[],[],[]]\n",
    "                place_cell_status = []\n",
    "                \n",
    "                for bin_centre, bin_occupancy in zip(cell_bin_center, cell_bin_occupancy):\n",
    "                    #Euclidean distance between all bins and all sandwells\n",
    "                    euc_dis_sw1.append(distance.euclidean(sw1_loc,bin_centre))\n",
    "                    euc_dis_sw2.append(distance.euclidean(sw2_loc,bin_centre))\n",
    "                    euc_dis_sw3.append(distance.euclidean(sw3_loc,bin_centre))\n",
    "                    \n",
    "            # ----------------------------------------------------------------------------------------                         \n",
    "            # Criteria:3 Only cells with >= 5 occupancy in bin centre (change on line below)\n",
    "            # ----------------------------------------------------------------------------------------                         \n",
    "                    if bin_occupancy >= 5:\n",
    "                        place_cell_status.append('y')\n",
    "                    else:\n",
    "                        place_cell_status.append('n')\n",
    "                    \n",
    "                euc_dis_sw1_all.append(euc_dis_sw1)\n",
    "                euc_dis_sw2_all.append(euc_dis_sw2)\n",
    "                euc_dis_sw3_all.append(euc_dis_sw3)\n",
    "                place_cell_status_all.append(place_cell_status)\n",
    "                \n",
    "            reward_well = events_dlc['well'][0]\n",
    "            \n",
    "            # ----------------------------------------------------------------------------------------                         \n",
    "            #Criteria 4: Only cells in the 95th pecentile are considered place cells\n",
    "            # ----------------------------------------------------------------------------------------                         \n",
    "            percentile = 95\n",
    "            place_cell_status = []\n",
    "            for i in range(len(perc_all)):\n",
    "                if perc_all[i] < percentile:\n",
    "                    for status in range(len(place_cell_status_all[i])):\n",
    "                        place_cell_status_all[i][status] = 'n'\n",
    "\n",
    "            #Create dataframe containing all cells + mutual information distribution and percentile\n",
    "            place_cell_data = {'Animal':list((input_animal,)*len(cells)),\n",
    "                               'Session':list((session,)*len(cells)),\n",
    "                               'Stage':list((stage,)*len(cells)),\n",
    "                               'Neuron':list(cells),\n",
    "                               'Place Cell Status':place_cell_status_all,\n",
    "                               'Place Cell Centre/Centres':bin_centres_all,\n",
    "                               'Place Cell Centre Event count':max_events_all,\n",
    "                               'Rewarded Well':list((reward_well,)*len(cells)),\n",
    "                               'Euclidean Distance from SW1':euc_dis_sw1_all, \n",
    "                               'Euclidean Distance from SW2':euc_dis_sw2_all,\n",
    "                               'Euclidean Distance from SW3':euc_dis_sw3_all,\n",
    "                               'Mutual_Information':mi_all,\n",
    "                               'Percentile':np.array(perc_all).flatten('F'),\n",
    "                               'Distribution':dist_all}\n",
    "\n",
    "            place_cell_table = pd.DataFrame(place_cell_data) \n",
    "\n",
    "            #Dataframe of other cells that werent analysed\n",
    "            cell_status = [x for x in all_traces_dlc.columns[11:] if x not in cells]\n",
    "            removed_cell_data = {'Animal':list((input_animal,)*len(cell_status)),\n",
    "                                 'Session':list((session,)*len(cell_status)),\n",
    "                                 'Stage':list((stage,)*len(cell_status)),\n",
    "                                 'Neuron':cell_status,\n",
    "                                 'Place Cell Status':list(('N/A',)*len(cell_status)),\n",
    "                                 'Place Cell Centre/Centres':list(('N/A',)*len(cell_status)),\n",
    "                                 'Place Cell Centre Event count':list(('N/A',)*len(cell_status)),\n",
    "                                 'Rewarded Well':list(('N/A',)*len(cell_status)),\n",
    "                                 'Euclidean Distance from SW1':list(('N/A',)*len(cell_status)), \n",
    "                                 'Euclidean Distance from SW2':list(('N/A',)*len(cell_status)),\n",
    "                                 'Euclidean Distance from SW3':list(('N/A',)*len(cell_status)),\n",
    "                                 'Mutual_Information':list(('N/A',)*len(cell_status)),\n",
    "                                 'Percentile':list(('N/A',)*len(cell_status)),\n",
    "                                 'Distribution':list(('N/A',)*len(cell_status))}\n",
    "\n",
    "            removed_cell_data = pd.DataFrame(removed_cell_data) \n",
    "            place_cell_table = place_cell_table.append(removed_cell_data)\n",
    "            # ----------------------------------------------------------------------------------------                         \n",
    "            # SAVE PLACE CELL TABLE\n",
    "            # ----------------------------------------------------------------------------------------                         \n",
    "            #Looks for place cell mutual info file - if it doesn't exist, it creates new one\n",
    "            try:\n",
    "                csv_place_cells = pd.read_csv('/Users/rufusmitchell-heggs/Desktop/data_analysis/projects/hippocampus/event_arena/secondary_analysis/'+input_animal+'/'+input_animal+'_place_cell_mutual_info.csv')\n",
    "            except FileNotFoundError:\n",
    "                #Creating new csv\n",
    "                place_cell_table.to_csv('/Users/rufusmitchell-heggs/Desktop/data_analysis/projects/hippocampus/event_arena/secondary_analysis/'+input_animal+'/'+input_animal+'_place_cell_mutual_info.csv', index=False)\n",
    "            else:\n",
    "                #If there is an existing CSV, this checks the animal, session and stage is already present, \n",
    "                #and asks if you want to add it again\n",
    "                csv_animal = csv_place_cells[csv_place_cells['Animal']==input_animal]\n",
    "                csv_session = csv_animal[csv_animal['Session']==session]\n",
    "                csv_stage = csv_session[csv_session['Stage']==stage]\n",
    "                if len(csv_stage) > 0:\n",
    "                    add_again = input('Animal '+input_animal+' Session '+ session+' Stage '+stage+' is already in csv table - are you sure you want to add it again? (y/n)')\n",
    "                    if add_again == 'y':\n",
    "                        place_cell_table.to_csv('/Users/rufusmitchell-heggs/Desktop/data_analysis/projects/hippocampus/event_arena/secondary_analysis/'+input_animal+'/'+input_animal+'_place_cell_mutual_info.csv', mode='a', header=False, index=False)\n",
    "                        print('Animal '+input_animal+' Session '+ session+' Stage '+stage+' added to csv table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
