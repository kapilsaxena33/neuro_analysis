{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place Cell Identification\n",
    "\n",
    "#### Three inputs:\n",
    "#### 1. input_animal:\n",
    "- H0466\n",
    "- H0422\n",
    "- etc\n",
    "\n",
    "#### 2. input_session: \n",
    "- all = run through all sessions and stages\n",
    "- N01\n",
    "- N02\n",
    "- I01\n",
    "- I02\n",
    "- A01\n",
    "- A02\n",
    "- P01\n",
    "- P02\n",
    "\n",
    "#### 3. input_stage:\n",
    "- PRE\n",
    "- SAM\n",
    "- CHO\n",
    "- PRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input desired session and stage\n",
    "input_animal = 'H0466'\n",
    "input_session = 'all'\n",
    "input_stage = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import place_cell_functions\n",
    "import multiprocessing as mp\n",
    "from _thread import start_new_thread\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    \n",
    "#plotting params\n",
    "mpl.rcParams['axes.facecolor'] = 'white'\n",
    "mpl.rcParams['axes.edgecolor'] = 'black'\n",
    "mpl.rcParams['axes.linewidth'] = '0.5'\n",
    "mpl.rcParams['axes.labelsize'] = '8'\n",
    "mpl.rcParams['axes.labelcolor'] = 'black'\n",
    "\n",
    "mpl.rcParams['xtick.color'] = 'black'\n",
    "mpl.rcParams['xtick.labelsize'] = '4'\n",
    "mpl.rcParams['ytick.labelsize'] = '4'\n",
    "mpl.rcParams['ytick.color'] = 'black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read iin LR events and trace files\n",
    "all_events_dlc = pd.read_csv('/Users/rufusmitchell-heggs/Desktop/data_analysis/preprocessing/event_arena/'+input_animal+'/output_directory/'+input_animal+'_event_dlc_LR.csv')\n",
    "all_traces_dlc = pd.read_csv('/Users/rufusmitchell-heggs/Desktop/data_analysis/preprocessing/event_arena/'+input_animal+'/output_directory/'+input_animal+'_trace_dlc_LR.csv')\n",
    "\n",
    "if input_session == 'all':\n",
    "    input_session = list(set(list(all_traces_dlc['Session'])))\n",
    "if input_stage == 'all':\n",
    "    input_stage = list(set(list(all_traces_dlc['stage'])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P02 CHO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P02 PRO\n",
      "P02 PRE\n",
      "P02 SAM\n",
      "N02 CHO\n",
      "Animal H0466 Session N02 Stage CHO is already in csv table - are you sure you want to add it again? (y/n)y\n",
      "N02 PRO\n",
      "N02 PRE\n",
      "N02 SAM\n",
      "A01 CHO\n",
      "Animal H0466 Session A01 Stage CHO is already in csv table - are you sure you want to add it again? (y/n)n\n",
      "A01 PRO\n",
      "A01 PRE\n",
      "A01 SAM\n",
      "I02 CHO\n",
      "Animal H0466 Session I02 Stage CHO is already in csv table - are you sure you want to add it again? (y/n)y\n",
      "I02 PRO\n",
      "I02 PRE\n",
      "I02 SAM\n",
      "P01 CHO\n",
      "P01 PRO\n",
      "P01 PRE\n",
      "P01 SAM\n",
      "N01 CHO\n",
      "Animal H0466 Session N01 Stage CHO is already in csv table - are you sure you want to add it again? (y/n)y\n",
      "N01 PRO\n",
      "N01 PRE\n",
      "N01 SAM\n",
      "A02 CHO\n",
      "Animal H0466 Session A02 Stage CHO is already in csv table - are you sure you want to add it again? (y/n)y\n",
      "A02 PRO\n",
      "A02 PRE\n",
      "A02 SAM\n",
      "I01 CHO\n",
      "Animal H0466 Session I01 Stage CHO is already in csv table - are you sure you want to add it again? (y/n)y\n",
      "I01 PRO\n",
      "I01 PRE\n",
      "I01 SAM\n"
     ]
    }
   ],
   "source": [
    "for session in input_session:\n",
    "    for stage in input_stage:\n",
    "        print(session, stage)\n",
    "        \n",
    "        #Session and stage selection based on input\n",
    "        traces = all_traces_dlc[all_traces_dlc['Session']==session][all_traces_dlc[all_traces_dlc['Session']==session]['stage']==stage]\n",
    "        events = all_events_dlc[all_events_dlc['Session']==session][all_events_dlc[all_events_dlc['Session']==session]['stage']==stage]\n",
    "        traces = traces.reset_index(drop=True)\n",
    "        events = events.reset_index(drop=True)\n",
    "        \n",
    "        #Remove any cells that are not registered during that session/stage\n",
    "        traces = traces.loc[:,(traces!=' nan').all()]\n",
    "\n",
    "        #List of cell IDs and their respective traces\n",
    "        cells = traces.columns\n",
    "        events = events[events.columns.intersection(cells)]\n",
    "        cell_ids = events.columns[8:]\n",
    "        \n",
    "        #Assign variable name to global identity\n",
    "        cells = cell_ids\n",
    "        trace_dlc = traces\n",
    "        events_dlc = events\n",
    "        \n",
    "        if len(events_dlc) != 0:\n",
    "\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "    #         # CRITERIA 1 - Cell sorting to manually remove bad traces\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "    #         num_cells_analysed = 0\n",
    "    #         for cell in cells:\n",
    "\n",
    "    #             #Allow user to see how many cells they have looked through\n",
    "    #             num_cells_analysed +=1\n",
    "    #             num_cells_left = len(cells)-1\n",
    "    #             print(cell, num_cells_analysed,'/',num_cells_left)\n",
    "\n",
    "    #             #plot the raw traces and overlapping events\n",
    "    #             plt.figure(figsize=(8, 1), dpi=400)\n",
    "    #             plt.plot(trace_dlc[str(cell)].astype(float), linewidth=0.5)\n",
    "    #             plt.plot(events_dlc[str(cell)].astype(float), linewidth=1)\n",
    "    #             plt.show()\n",
    "\n",
    "    #             #Option to remove any bad cells\n",
    "    #             good_events = input(\"Are all events good - y/n?\")\n",
    "    #             if good_events != 'y':\n",
    "    #                 print(bcolors.FAIL+cell,'Dropped'+bcolors.ENDC)\n",
    "    #                 trace_dlc = trace_dlc.drop([cell], axis=1)\n",
    "    #                 events_dlc = events_dlc.drop([cell], axis=1)\n",
    "\n",
    "    #             else:\n",
    "    #                 print(bcolors.OKGREEN+cell,'Accepted'+bcolors.ENDC)\n",
    "\n",
    "    #         #Update cells being analysed list\n",
    "    #         cells = events_dlc.columns[8:]\n",
    "\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "            # CRITERIA 2 - all cells with events lower than 0.3 = 0\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "            # for cell in cells:\n",
    "            #     a = np.array(events_dlc[cell].values.tolist())\n",
    "            #     events_dlc[str(cell)] = np.where(a <= 0.3, 0, a).tolist() # <--- Condition, ignore events lower than 0.3\n",
    "            #     events_dlc[str(cell)] = np.where(a >= 0.3, 1, a).tolist() # <--- Binarize events\n",
    "            #     if sum(events_dlc[cell])<3:\n",
    "            #         events_dlc = events_dlc.drop([cell], axis=1)\n",
    "\n",
    "            for cell in cells:\n",
    "                a = np.array(events_dlc[cell].values.tolist())\n",
    "                events_dlc[str(cell)] = np.where(a > 0, 1, a).tolist() # <--- Binarize events\n",
    "                if sum(events_dlc[cell])<3:\n",
    "                    events_dlc = events_dlc.drop([cell], axis=1)\n",
    "                    trace_dlc = trace_dlc.drop([cell], axis=1)\n",
    "\n",
    "            cells = events_dlc.columns[8:]\n",
    "            for cell in trace_dlc.columns:\n",
    "                if cell not in events.columns:\n",
    "                    trace_dlc = trace_dlc.drop([cell], axis=1)\n",
    "\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "            # OCCUPANCY VECTOR GENERATOR\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "\n",
    "            #Defining the boundaries of the arena\n",
    "            xedges = np.arange(0, 700, 720/33)\n",
    "            yedges = np.arange(0, 600, 500/33)\n",
    "\n",
    "            #Extract the DLC x,y coordinates\n",
    "            x = events_dlc['x']\n",
    "            y = events_dlc['y']\n",
    "\n",
    "            #Create occupancy map vector\n",
    "            occupancy_map = []\n",
    "            for x_pos, y_pos in zip(x,y):\n",
    "                for y_bin in range(len(yedges)):\n",
    "                    if y_bin < len(yedges)-1:\n",
    "                        if  yedges[y_bin] <= y_pos <= yedges[y_bin+1]:\n",
    "                            for x_bin in range(len(xedges)):\n",
    "                                if x_bin < len(xedges)-1:\n",
    "                                    if xedges[x_bin] <= x_pos <= xedges[x_bin+1]:\n",
    "                                        occupancy_map.append(int(str(y_bin)+str(x_bin)))\n",
    "\n",
    "            # ----------------------------------------------------------------------------------------                         \n",
    "            # SPATIAL MUTUAL INFORMATION for each cell, the percentile and the shuffled distribution\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "\n",
    "            pool = mp.Pool(processes=4)\n",
    "            results = [pool.apply_async(place_cell_functions.mi_perc_dis, args=(np.array(events_dlc[str(cell)]),occupancy_map)) for cell in cells]\n",
    "            mi_all, perc_all, dist_all = np.array([p.get() for p in results]).transpose()\n",
    "            perc_all = np.array([item for sublist in perc_all for item in sublist])\n",
    "            end = time.time()\n",
    "\n",
    "            # ----------------------------------------------------------------------------------------                         \n",
    "            #Criteria 3 - Only cells in the 95th pecentile are considered place cells\n",
    "            # ----------------------------------------------------------------------------------------                         \n",
    "            percentile = 95\n",
    "            place_cell_status = []\n",
    "            for perc in perc_all:\n",
    "                if perc > percentile:\n",
    "                    place_cell_status.append('y')\n",
    "                else:\n",
    "                    place_cell_status.append('n')\n",
    "\n",
    "\n",
    "            #Create dataframe containing all cells + mutual information distribution and percentile\n",
    "            place_cell_data = {'Animal':list((input_animal,)*len(cells)),'Session':list((session,)*len(cells)),'Stage':list((stage,)*len(cells)),\n",
    "                               'Neuron':list(cells),'Status':place_cell_status,'Mutual_Information':mi_all,\n",
    "                               'Percentile':np.array(perc_all).flatten('F'),'Distribution':dist_all}\n",
    "\n",
    "            place_cell_table = pd.DataFrame(place_cell_data) \n",
    "\n",
    "            #Dataframe of other cells that werent analysed\n",
    "            cell_status = [x for x in all_traces_dlc.columns[8:] if x not in cells]\n",
    "            removed_cell_data = {'Animal':list((input_animal,)*len(cell_status)),'Session':list((session,)*len(cell_status)),\n",
    "                                 'Stage':list((stage,)*len(cell_status)),'Neuron':cell_status,'Status':list(('N/A',)*len(cell_status)),\n",
    "                                 'Mutual_Information':list(('N/A',)*len(cell_status)),'Percentile':list(('N/A',)*len(cell_status)),\n",
    "                                 'Distribution':list(('N/A',)*len(cell_status))}\n",
    "\n",
    "            removed_cell_data = pd.DataFrame(removed_cell_data) \n",
    "            place_cell_table = place_cell_table.append(removed_cell_data)\n",
    "            # ----------------------------------------------------------------------------------------                         \n",
    "            # SAVE PLACE CELL TABLE\n",
    "            # ----------------------------------------------------------------------------------------                         \n",
    "            #Looks for place cell mutual info file - if it doesn't exist, it creates new one\n",
    "            try:\n",
    "                csv_place_cells = pd.read_csv('/Users/rufusmitchell-heggs/Desktop/data_analysis/projects/hippocampus/event_arena/secondary_analysis/'+input_animal+'/'+input_animal+'_place_cell_mutual_info.csv')\n",
    "            except FileNotFoundError:\n",
    "                #Creating new csv\n",
    "                place_cell_table.to_csv('/Users/rufusmitchell-heggs/Desktop/data_analysis/projects/hippocampus/event_arena/secondary_analysis/'+input_animal+'/'+input_animal+'_place_cell_mutual_info.csv', index=False)\n",
    "            else:\n",
    "                #If there is an existing CSV, this checks the animal, session and stage is already present, \n",
    "                #and asks if you want to add it again\n",
    "                csv_animal = csv_place_cells[csv_place_cells['Animal']==input_animal]\n",
    "                csv_session = csv_animal[csv_animal['Session']==session]\n",
    "                csv_stage = csv_session[csv_session['Stage']==stage]\n",
    "                if len(csv_stage) > 0:\n",
    "                    add_again = input('Animal '+input_animal+' Session '+ session+' Stage '+stage+' is already in csv table - are you sure you want to add it again? (y/n)')\n",
    "                    if add_again == 'y':\n",
    "                        place_cell_table.to_csv('/Users/rufusmitchell-heggs/Desktop/data_analysis/projects/hippocampus/event_arena/secondary_analysis/'+input_animal+'/'+input_animal+'_place_cell_mutual_info.csv', mode='a', header=False, index=False)\n",
    "                        print('Animal '+input_animal+' Session '+ session+' Stage '+stage+' added to csv table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
